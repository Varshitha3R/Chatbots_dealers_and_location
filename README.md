
# ğŸ“ ZipCode Location Q&A Assistant with Chatbot Memory

An intelligent Flask-based web application that helps users retrieve relevant location-based information using semantic search powered by **OpenAI embeddings**, **LangChain**, and **LangGraph**. This application maintains session memory, allowing it to remember past interactions across different queries, providing a more personalized and context-aware experience.

---

## ğŸš€ Features

- ğŸ” **Semantic Search** using cosine similarity
- ğŸ¤– **GPT-4 Powered Answers** using OpenAI API
- ğŸ“ Uses CSV file (`loc_emb.csv`) for location content + vector embeddings
- ğŸ§  Integrates **LangChain's OpenAIEmbeddings**
- ğŸŒ CORS enabled â€” ready for frontend integration
- ğŸ’¬ Interactive POST endpoint for query-response
- ğŸ§‘â€ğŸ’» Simple HTML front end (`location.html`)
- ğŸ§  **Session Memory** with LangGraph to remember past user interactions
- ğŸ”‘ **Session Management** with `session_id` for personalized interaction

---

## ğŸ“‚ Project Structure

```
zipcode/
â”‚
â”œâ”€â”€ app.py               # Flask backend
â”œâ”€â”€ location.html        # Frontend (can be extended)
â”œâ”€â”€ loc_emb.csv          # Location content + precomputed embeddings
â”œâ”€â”€ langraph.py          # Chatbot memory and session management (LangGraph)
â”œâ”€â”€ .env                 # Environment variables (e.g., OpenAI key)
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/zipcode-assistant.git
cd zipcode-assistant
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Add Your API Key

Create a `.env` file in the root directory and add your OpenAI API key:

```
OPENAI_API_KEY=your_openai_api_key_here
```

### 5. Run the App

```bash
python app.py
```

App will be live at: [http://localhost:5000](http://localhost:5000)

---

## ğŸ”Œ API Endpoints

### `POST /chat`

Get a smart location-based answer while maintaining session memory.

**Request:**

```json
{
  "question": "Tell me about the Atlanta distribution center.",
  "session_id": "optional-session-id"
}
```

**Response:**

```json
{
  "Answer": "<b>Location:</b> Atlanta, Georgia <ul><li>Details...</li></ul>",
  "Similarity": 0.89
}
```

The `session_id` is used to maintain conversation history and context. If provided, the chatbot will reference previous interactions for a more personalized response.

---

### `GET /chat`

Currently not implemented â€” placeholder for session handling and retrieving past interactions.

---

## ğŸ’¬ Chatbot Memory with LangGraph

The chatbot leverages **LangGraph** for **session memory**. Each user query is associated with a `session_id`, which allows the bot to:

- Remember previous queries
- Provide context-aware responses across different sessions
- Personalize interactions by referencing past user behavior

`langraph.py` is responsible for managing the memory and ensuring context is maintained.

---

## ğŸ“‹ Notes

- `loc_emb.csv` must contain two fields: `Content` and `embedding`
- Embeddings must be stored in stringified list format
- OpenAI GPT-4 and embedding API usage require valid API key
- Responses are formatted using basic HTML (`<b>`, `<ul>`, `<li>`, `<i>`)
- **Session Memory** relies on LangGraph, and it uses the `session_id` to manage conversation history.

---

---

## ğŸ™Œ Contact

**Author:** Varshitha R
ğŸ“§ varshitharavi315@gmail.com
ğŸ”— [[LinkedIn](https://www.linkedin.com/in/your-profile)  ](https://www.linkedin.com/in/varshithar31/)


---
```

